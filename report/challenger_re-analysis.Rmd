---
title: "W271 Group Lab 1"
subtitle: "Investigating the 1986 Space Shuttle Challenger Accident"
author: "Please fill in with your names."
output: bookdown::pdf_document2
fontsize: 11pt
geometry: margin=1in
---

\newpage

```{=tex}
\begin{abstract} 
This report will, indeed, be abstract. No, instead, describe your goals your approach, and what you learn.
In this study, we are investigating the effect of physical condition such as temperature and pressure have on the odds of O Rings failure on a space shuttle. 
\end{abstract}
```
# Introduction

## Research question

Does a various physical conditions, in term of temperature and pressure, effect the odds of O-Rings failures on a shuttle?

# Data (20 points)

**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report. The Data Section of this report is worth 20 points.**

-   Conduct a thorough EDA of the data set.

    -   This should include both graphical and tabular analysis as taught in this course.
    -   Since the report has a page-limit, you will have to be selective when choosing visuals to illustrate your key points, associated with a concise explanation of the visuals.

-   This EDA should begin with an inspection of the given dataset; examination of anomalies, missing values, potential of top and/or bottom code etc.
```{r load packages for homework 2, message=FALSE}
#install.packages("MASS")
#install.packages("ggplot2")
#install.packages("sandwich")
#install.packages("stargazer")
#install.packages("mcprofile")
#install.packages("Hmisc")
#install.packages("patchwork")
#install.packages("car")
library(tidyverse)
library(patchwork)
library(gridExtra)
library(Hmisc)

# multinomial regression
library(nnet)

# car pacakge for testing
library(car)

library(sandwich)
library(knitr)
library(stargazer)
library(mcprofile)
library(Hmisc)
library(gridExtra)
```

```{r read challenger data, message=FALSE}
challenger <- read_csv("../data/raw/challenger.csv")
```

```{r tabular EDA, message = FALSE}
head(challenger)
glimpse(challenger)
summary(challenger)
describe(challenger)
```

```{r Analysis of Response Variable}
tab <- xtabs(~ O.ring, data = challenger)
names(tab)

x <- as.numeric(names(tab))

plot(x, tab, type='bar', main="Number of O-Ring Failed by Flights",
     xlab="Number of O-rings failed", ylab="Frequency")
```

## Description

**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report.**

-   Describe the data that you are using. How is this data generated, what is the sampling process that brought it to your availability. If it is helpful, you might describe the population (i.e. the Random Variables) that exist and how samples are produced from these random variables.
-   The authors use logistic regression to estimate the probability an O-ring will fail. In order to use this model, the authors needed to assume that each O-ring is independent for each launch. Discuss why this assumption is necessary and the potential problems with it. Note that a subsequent analysis helped to alleviate the authors' concerns about independence.

## Key Features

```{r}
p1 <- challenger %>%
    ggplot(aes(x = Temp)) + geom_density(aes(y = ..density..,
    color = factor(O.ring), fill = factor(O.ring)), alpha = 0.2) + ggtitle("Distribution of Temp") +
    theme(plot.title = element_text(lineheight = 1, face = "bold")) +
    xlab("Temp") + ylab("Density")

p2 <- challenger %>%
    ggplot(aes(x = Pressure)) + geom_density(aes(y = ..density..,
    color = factor(O.ring), fill = factor(O.ring)), alpha = 0.2) + ggtitle("Distribution of Pressure") +
    theme(plot.title = element_text(lineheight = 1, face = "bold")) +
    xlab("Pressure") + ylab("Density")

p3 <- challenger %>%
    ggplot(aes(factor(O.ring), Temp)) + geom_boxplot(aes(fill = factor(O.ring))) +
    coord_flip() + ggtitle("Temp by Number of Oring Incidents") +
    theme(plot.title = element_text(lineheight = 1, face = "bold")) +
    ylab("Temp") + xlab("O.ring")

p4 <- challenger %>%
    ggplot(aes(factor(O.ring), Pressure)) + geom_boxplot(aes(fill = factor(O.ring))) +
    coord_flip() + ggtitle("Pressure by Number of Oring Incidents") +
    theme(plot.title = element_text(lineheight = 1, face = "bold")) +
    ylab("Pressure") + xlab("O.ring")

grid.arrange(p1, p2)
grid.arrange(p3, p4)
```

For our study, we noted two features, temperature and pressure, that most likely affect the odds of O-rings failure on a space shuttle. From the distribution and box plot, the number of O-rings failed has a higher distribution at the lower temperature. In term of pressure, the distribution plots showed that 0 failed O-rings at both high and low pressure while 2 failed O-rings showed a uniform distribution. However, it is noted that this plot does somewhat show that the number of O-rings failed is higher for higher pressure and lower for lower pressure.  

# Analysis

## Reproducing Previous Analysis (10 points)

**Your analysis should address the following two questions. In your final submission, please remove this question prompt so that your report reads as a report.**

1.  Estimate the logistic regression model that the authors present in their report -- include the variables as linear terms in the model. Evaluate, using likelihood ratio tests, the statistical significance of each explanatory variable in the model. Evaluate, using the context and data understanding that you have created in the **Data** section of this report, the practical significance of each explanatory variable in the model.

```{r}
# Since there are 6 Orings on a shuttle
# We define the failure rates as number of O Rings Failed out of 6 O Rings
# let's define some small epsilon to address log of 0
# do stuff
challenger$failure_rate <- challenger$O.ring/challenger$Number

mod1 <- glm(formula = cbind(O.ring, Number-O.ring) ~ Temp + Pressure, 
            family = binomial(link="logit"),
            data = challenger)
summary(mod1)

Anova(mod1)

mod1 <- glm(formula=failure_rate~Temp+Pressure,
            data=challenger,
            family=binomial(link="logit"))

summary(mod1)

```

2.  Dalal, Fowlkes, and Hoadley (1989) chose to remove `pressure` from the model based on their likelihood ratio tests. Critically evaluate, using your test results and understanding of the question and data, whether `pressure` should be included in the model, or instead, `pressure` should not be included in the model. Your report needs to make a determination, argue why it is most appropriate choice, and make note of how (if at all) the model results are affected by the choice of including or excluding `pressure`.

```{r}
Anova(mod1, test='LR')
```

## Confidence Intervals (20 points)

No matter what you determined about using or dropping `pressure`, for this section begin by considering the simplified model $logit(\pi) = \beta_0 + \beta_1 Temp$, where $\pi$ is the probability of an O-ring failure. Complete the following:

1.  Estimate the logistic regression model.
2.  Determine if a quadratic term is needed in the model for the temperature in this model.
3.  Construct two plots:
4.  $\pi$ vs. Temp; and,
5.  Expected number of failures vs. Temp.

Specific requirements for these plots:

-   Use a temperature range of 31° to 81° on the x-axis even though the minimum temperature in the data set was 53°.\
-   Include the 95% Wald confidence interval bands for $\pi$ on the plot. Describe, in your analysis of these plots, why the bands much wider for lower temperatures than for higher temperatures?

```{r}
##############################################################################
# Estimate the logistic regression model
##############################################################################
mod2 <- glm(formula=cbind(O.ring, Number-O.ring)~Temp,
            family = binomial(link="logit"),
            data=challenger)
summary(mod2)

mod3 <- glm(formula=cbind(O.ring, Number-O.ring)~Temp+I(Temp^2),
            family = binomial(link="logit"),
            data=challenger)
summary(mod3)

# 2. determine if quadratic term is needed
anova(mod2, mod3, test='Chisq')

# 3. Graph pi vs Temp
coef <- mod2$coefficients
xx = c(1)
z = coef[1]*xx[1]
x <- challenger$Temp


##############################################################################
# Estimate the logistic regression model
##############################################################################
mod2 <- glm(formula=failure_rate~Temp,
            data=challenger,
            family=binomial(link="logit"))
summary(mod2)
mod3 <- glm(formula=failure_rate~Temp+I(Temp^2),
            data=challenger,
            family=binomial(link="logit"))
summary(mod3)
```
```{r}
##############################################################################
# 2. Determine if quadratic term is needed
##############################################################################
anova(mod2,mod3,test='Chisq')
```

```{r}
##############################################################################
# 3. Pi vs Temp
##############################################################################
mod.beta <- mod2$coefficients
# Reproduce the graph overlaying the same result from the linear model as a comparison
curve(expr = exp(mod.beta[1] + mod.beta[2]*x)/(1+exp(mod.beta[1] + mod.beta[2]*x)),
    xlim = c(31, max(challenger$Temp)),
    ylim = c(0,1),
    col = "blue", 
    main = expression(pi == frac(e^(z + coef[inc]*Temp), 
                                 1+e^(z+coef[inc]*Temp))),
      xlab =  expression(Temp), ylab = expression(pi))
par(new=TRUE)


# calculate true wald confidence interval at temperature
wald.CI.true.coverage = function(mod, temp) {
  alpha = 0.5
  predict.data <- data.frame(Temp = temp)
  linear.pred = predict(object = mod, newdata = predict.data, type = "link", se = TRUE)
  pi.hat = exp(linear.pred$fit)/(1+exp(linear.pred$fit))
  CI.lin.pred = linear.pred$fit + qnorm(p = c(alpha/2, 1-alpha/2))*linear.pred$se.fit
  CI.pi = exp(CI.lin.pred)/(1+exp(CI.lin.pred))
  wald.df = round(data.frame(temp, lower=CI.pi[1], upper=CI.pi[2]),4)
  return(wald.df)
}

temp.seq = seq(31, 81, by=1)
wald.CI.true.matrix = matrix(data=NA,nrow=length(temp.seq),ncol=3)
counter=1
for (temp in temp.seq) {
  wald.df2 = wald.CI.true.coverage(mod2, temp) 
  wald.CI.true.matrix[counter,] = c(temp, wald.df2$lower, wald.df2$upper)
  counter = counter+1
}
wald.CI.true.matrix[1:5,]

# plot lower bound
lines(x=temp.seq,
     y=wald.CI.true.matrix[,2],
     ylim=c(0,1),
     type="l",
     lty="dotted",
     col="red")

# plot upper bound
lines(x=temp.seq,
     y=wald.CI.true.matrix[,3],
     ylim=c(0,1),
     type="l",
     lty="dotted",
     col="red")

##############################################################################
# 4. Graph Expected number of failures vs Temp
##############################################################################
curve(expr = 6*exp(mod.beta[1] + mod.beta[2]*x)/(1+exp(mod.beta[1] + mod.beta[2]*x)),
    xlim = c(31, max(challenger$Temp)),
    ylim = c(0,6),
    col = "blue", 
    xlab =  expression(Temp), ylab = "Expected Number of Failures")
par(new=TRUE)

```
> Intervals are wide for temperatures less than 65F is wide and short for temperatures greater than 65F. This is expected, because most of the data have temperatures greater than 65F. The estimated interval for temperature equal to 30F is about (1,6); this illustrates that we have high variability for the expected number of incidents.


3.  The temperature was 31° at launch for the Challenger in 1986. Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval. Discuss what assumptions need to be made in order to apply the inference procedures.
```{r}
new.data <- data.frame('Temp' = 31)
pred.prob <- predict(mod2, newdata = new.data, type='link', se = TRUE)
pi <- exp(pred.prob$fit)/(1+exp(pred.prob$fit))

linear.Wald.CI <- pred.prob$fit + qnorm(p=c(0.025, 0.975))*pred.prob$se
Wald.CI <- exp(linear.Wald.CI)/(1+exp(linear.Wald.CI))

ChallengerSpaceLaunch <- data.frame(pi.hat = pi, lower = Wald.CI[1], upper = Wald.CI[2] )
ChallengerSpaceLaunch
```

```{r}
params = dim(summary(mod2)$coefficients)[1]
predict.data = matrix(data=c(1,31),
                       nrow=1,
                       ncol=params)
linear.combo = mcprofile(object = mod2, CM=predict.data)
mroz_logit_profile = confint(linear.combo, level=0.95)
mroz_logit_ci = exp(mroz_logit_profile$confint)/(1+exp(mroz_logit_profile$confint))
mroz_logit_estimate = exp(mroz_logit_profile$estimate)/(1+exp(mroz_logit_profile$estimate))
result.profile_lr = data.frame(estimate=mroz_logit_estimate,
                               lower=mroz_logit_ci$lower,
                               upper=mroz_logit_ci$upper)
result.profile_lr

```


## Bootstrap Confidence Intervals (30 points)

Rather than relying on asymptotic properties, consider using a parametric bootstrap, as did Dalal, Fowlkes and Hoadley. To do this:

1.  Simulate a large number of data sets (n = 23 for each) by re-sampling with replacement from the data.
2.  Estimate a model for each dataset.
3.  Compute the effect at a specific temperature of interest.

```{r resample with replacement}
# TODO: create a for loop to do this,
# for each data set:
# for each model from the resulting data set:
# compute the probability at each integer temeprature value (10 to 100)
# compute the CI for the probability
temp <- NULL
pi.hat <- NULL
CI.lower <- NULL
CI.upper <- NULL

for (i in 1:100) {
  challenger_resampled <- NULL
  
  # creating a resampled data from the original dataset with replacement
  challenger_resampled <- challenger[sample(nrow(challenger), size=23, replace = TRUE), ]
  
  # construct a model from the new resampled dataset
  mod_resample <- glm(formula=cbind(O.ring, Number-O.ring)~Temp,
              family = binomial(link="logit"),
              data=challenger_resampled)
  output <- NULL
  conf.lower <- NULL
  conf.upper <- NULL
  tprime <- NULL
  # run the model though to obtain the output
  for (t in 10:100) {
    new.data <- data.frame('Temp' = t)
    pred.prob <- predict(mod_resample, newdata = new.data, type='link', se = TRUE)
    
    # compute probability and CI
    pi <- exp(pred.prob$fit)/(1+exp(pred.prob$fit))
    linear.Wald.CI <- pred.prob$fit + qnorm(p=c(0.05, 0.95))*pred.prob$se
    Wald.CI <- exp(linear.Wald.CI)/(1+exp(linear.Wald.CI))
    # append data to array
    tprime <- c(tprime, t)
    output <- c(output, pi)
    conf.lower <- c(conf.lower, Wald.CI[1])
    conf.upper <- c(conf.upper, Wald.CI[2])
  }
  
  # append each bootstrap run
  temp <- c(temp, tprime)
  pi.hat <- c(pi.hat, output)
  CI.lower <- c(CI.lower, conf.lower)
  CI.upper <- c(CI.upper, conf.upper)
}

bootstrap_ouptuts <- data.frame(temp = temp, pi.hat = pi.hat, 
                                lower = CI.lower, upper = CI.upper)

agg_tbl <- bootstrap_ouptuts %>% group_by(temp) %>% 
               summarise(pi.hat = mean(pi.hat), 
                         lower = mean(lower), 
                         upper = mean(upper)) 
```

```{r plot some QQ plots}
# sliced the data on 1 temperature unit
t <- 35
sliced_df <- bootstrap_ouptuts[bootstrap_ouptuts$temp == t, ]

# Draw two plots next to each other
par(mfrow = c(1, 2))
#normal_density <- dbinom(27, size=100, prob=0.25)
zs <- seq(0, 1, 0.01)

hist_ <- function(x, ...){
  hist(x, breaks = 30, xlab = "Z", ylab = "",  yaxt='n', freq = FALSE, ...)
  #lines(zs, normal_density, type = "l", col = "red", lwd = 2)
}

hist_(sliced_df$pi.hat, main = "Gaussian Distribution",xlim = c(0, 1))
qqnorm(sliced_df$pi.hat)
qqline(sliced_df$pi.hat, col = "blue", lwd = 2)
```
To produce a confidence interval, the authors used the 0.05 and 0.95 observed quantiles from the simulated distribution as their 90% confidence interval limits.

Using the parametric bootstrap, compute 90% confidence intervals separately at each integer temperature between 10° and 100° Fahrenheit.

In this section, you should describe your process, justify such a process, and present your results in a way that is compelling for your reader.

## Alternative Specification (10 points)

With the same set of explanatory variables in your final model, estimate a linear regression model. Explain the model results; conduct model diagnostic; and assess the validity of the model assumptions. Would you use the linear regression model or binary logistic regression in this case? Explain why.

# Conclusions (10 points)

Interpret the main result of your preferred model in terms of both odds and probability of failure. Summarize this result with respect to the question(s) being asked and key takeaways from the analysis.
