---
title: "W271 Group Lab 1"
subtitle: "Investigating the 1986 Space Shuttle Challenger Accident"
author: "Ray Cao, Ken Trinh, Lisa Wu, Sophie Yeh"
output: bookdown::pdf_document2
fontsize: 11pt
geometry: margin=1in
---

\newpage

```{=tex}
\begin{abstract} 
In this study, we are investigating the effect of physical condition such as temperature and pressure have on the odds of O Rings failure on a space shuttle. 
\end{abstract}
```
# Introduction

## Research question

How do temperature and pressure affect the odds of o-ring failures on a shuttle launch?

# Data (20 points)

```{asis, echo=FALSE}
**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report. The Data Section of this report is worth 20 points.**

-   Conduct a thorough EDA of the data set.

    -   This should include both graphical and tabular analysis as taught in this course.
    -   Since the report has a page-limit, you will have to be selective when choosing visuals to illustrate your key points, associated with a concise explanation of the visuals.

-   This EDA should begin with an inspection of the given dataset; examination of anomalies, missing values, potential of top and/or bottom code etc.
```

```{r load packages for homework 2, echo=FALSE, message=FALSE, warning=FALSE}
# install.packages("MASS")
# install.packages("ggplot2")
# install.packages("sandwich")
# install.packages("stargazer")
# install.packages("mcprofile")
# install.packages("Hmisc")
# install.packages("patchwork")
# install.packages("car")
library(tidyverse)
library(patchwork)
# multinomial regression
library(nnet)
# car pacakge for testing
library(car)
library(sandwich)
library(knitr)
library(stargazer)
library(mcprofile)
library(Hmisc)
library(gridExtra)

theme_set(theme_minimal())
knitr::opts_chunk$set(tidy.opts = list(width_cutoff = 100), tidy = TRUE, message = FALSE, warning = FALSE)
rm(list = ls())
```


```{r read-challenger-data, echo=FALSE, message=FALSE}
challenger <- read_csv("../data/raw/challenger.csv")
```

```{r tabular-EDA, echo=FALSE, include = FALSE, message=FALSE}
glimpse(challenger)
summary(challenger)
describe(challenger)
nulls <- sum(is.na(challenger))
cat(nulls, "missing values in the data set.")
```

We conducted a thorough EDA analysis to gather information of the two potential explanatory variables (temperature and pressure) and the response variable (O.ring). The plots below provide distribution of the three variables and the scatter plot of Temperature vs O.ring.

```{r Analysis-of-Response-Variable, echo=FALSE, message=FALSE, fig.align='center',out.width="75%", out.height="50%", fig.cap="Distribution and Scatter Plots of Key Variables"}

d1 <- challenger %>%
  ggplot(aes(x = Temp, y = ..prop.., group = 1)) +
  geom_bar(fill = "DarkBlue", color = "black") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -1) +
  geom_vline(aes(xintercept = mean(Temp)), color = " red", linetype = "dashed") +
  # ggtitle("Distribution of Temperature") + 
  # theme(plot.title = element_text(lineheight=1, face="bold")) +
  xlab("Temperature") +
  ylab("Proportion")

d2 <- challenger %>%
  ggplot(aes(x = Pressure, y = ..prop.., group = 1)) +
  geom_bar(fill = "DarkBlue", color = "black") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -1) +
  xlab("Pressure") +
  ylab("Proportion") +
  ylim(0, 1)

d3 <- challenger %>%
  ggplot(aes(x = O.ring, y = ..prop.., group = 1)) +
  geom_bar(fill = "DarkBlue", color = "black") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -1) +
  xlab("Number of Failed O-Rings") +
  ylab("Proportion") +
  ylim(0, 1)

d4 <- challenger %>%
  ggplot(aes(x = Temp, y = O.ring)) + geom_point() +   xlab("Temperature")

grid.arrange(d1,d2, d3, d4, ncol=2)
```

## Description
```{asis, echo=FALSE}
**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report.**

-   Describe the data that you are using. How is this data generated, what is the sampling process that brought it to your availability. If it is helpful, you might describe the population (i.e. the Random Variables) that exist and how samples are produced from these random variables.
-   The authors use logistic regression to estimate the probability an O-ring will fail. In order to use this model, the authors needed to assume that each O-ring is independent for each launch. Discuss why this assumption is necessary and the potential problems with it. Note that a subsequent analysis helped to alleviate the authors' concerns about independence.
```

This data set was sourced from 23 space shuttle launches before the Challenger launch. It contains 5 columns: Flight, Temp, Pressure, O.ring, Number. Flight is a unique identifier representing each launch. Number represents the total number (6) of O-rings in each shuttle. O.ring is the response variable and denotes the number of O-rings failed at each launch. Lastly, Temp and Pressure (the two potential explanatory variables) denote the numerical values measured at each launch. 

There are no missing data for any of the five columns in the data set. Temperature has 16 distinct values, ranging from 53 to 81 with a mean of 69.57. Pressure has 3 distinct values (50, 100, 200) with a mean of 152. Both temperature and pressure records are full integer value. For the response variable O.ring, 16 out of 23 launches have 0 failed O-ring, 5 observations have 1 failed O-ring and 2 observations have 2 failed O-rings.
 
In the original study, the researchers treated each of the 6 O-rings as independent for each launch. In other words, the failure of one O-ring has no impact on any other O-rings. This assumption is necessary to satisfy the independence assumption of the binomial model. The binomial model also assumes that each O-ring has equal probability of being damaged by either temperature or pressure. By assuming independence, the researcher did not account for the fact that a single failed O-ring could cause the other o-ring or the entire launch to fail. While careful evaluation of the potential dependency between each O-ring is necessary, we will assume independence in this analysis. A binary logistic regression could alleviate the independence concern.

## Key Features

From the plots in Figure 2, we observed that O.ring failures (1 or 2) tend to occur at lower temperature. Higher temperature launches tend to have fewer O-ring failures. In term of pressure, we did not see clear evidence of the impact of pressure on O-ring failures, as zero O-ring failures are evenly distributed across all pressure points. 5 incidents of 1 failed O-ring happened at both low and high pressure and 2 incidents of 2 failed O-rings occurred at high pressure.  

We will use both temperature and pressure as explanatory variable to evaluate their effect on the odds of O-ring failures. This will help us answer the research question whether temperature and pressure affect the odds of O-ring failures on a shuttle launch.

```{r echo=FALSE, message=FALSE, fig.align='center', out.width="75%", fig.cap="O-ring Failure Distribution Plots for Temperature and Pressure", warning=FALSE}
p1 <- challenger %>%
  ggplot(aes(x = Temp)) +
  geom_density(aes(
    y = ..density..,
    color = factor(O.ring), fill = factor(O.ring)
  ), alpha = 0.2) +
  ggtitle("Distribution of Temp") +
  theme(plot.title = element_text(lineheight = 1, face = "bold")) +
  xlab("Temperature") +
  ylab("Density")

p2 <- challenger %>%
  ggplot(aes(x = Pressure)) +
  geom_density(aes(
    y = ..density..,
    color = factor(O.ring), fill = factor(O.ring)
  ), alpha = 0.2) +
  ggtitle("Distribution of Pressure") +
  theme(plot.title = element_text(lineheight = 1, face = "bold")) +
  xlab("Pressure") +
  ylab("Density")

p3 <- challenger %>%
  ggplot(aes(Temp, factor(O.ring))) +
  geom_boxplot(aes(fill = factor(O.ring))) +
  ggtitle("Temp by O.ring Incidents") +
  theme(plot.title = element_text(lineheight = 1, face = "bold")) +
  xlab("Temperature") +
  ylab("O-ring")

p4 <- challenger %>%
  ggplot(aes(Pressure, factor(O.ring))) +
  geom_boxplot(aes(fill = factor(O.ring))) +
  ggtitle("Pressure by O.ring Incidents") +
  theme(plot.title = element_text(lineheight = 1, face = "bold")) +
  xlab("Pressure") +
  ylab("O-ring")

grid.arrange(p1, p2, p3, p4, ncol=2)
```


# Analysis

## Reproducing Previous Analysis (10 points)
```{asis, echo=FALSE}
**Your analysis should address the following two questions. In your final submission, please remove this question prompt so that your report reads as a report.**

1.  Estimate the logistic regression model that the authors present in their report -- include the variables as linear terms in the model. Evaluate, using likelihood ratio tests, the statistical significance of each explanatory variable in the model. Evaluate, using the context and data understanding that you have created in the **Data** section of this report, the practical significance of each explanatory variable in the model.
```

Our baseline model is a binomial logistic regression model that replicates what the authors presented in their original report. See R codes and the model summary table below.

```{r model-1-temp-and-pressure, message=FALSE}
mod1 <- glm(formula = cbind(O.ring, Number - O.ring) ~ Temp + Pressure,
  family = binomial(link = "logit"), data = challenger)
```

```{r model-1-stargazer, results = "asis",  message = FALSE, echo=FALSE, warning=FALSE}
stargazer(mod1,  header=FALSE,
  type = "latex", omit.stat = c("f", "ser"),
  covariate.labels = c("Temperature", "Pressure", "(Intercept)"),
  report = ("vc*p"),
  star.cutoffs = c(0.05, 0.01, 0.001),
  title = "The Estimated Relationship Between O-Rings Failure and Temperature/Pressure",
  dep.var.caption = "Output Variable: Log Odds of O-Rings Failure",
  dep.var.labels = "",
  column.sep.width = "-8pt"
)
```

```{r model-1-OR}
#Impact on odds of O-ring failure for a 10-unit increase of temperature or pressure 
OR1 <- round(exp(10 * mod1$coefficients), 3)[2]
OR2 <- round(exp(10 * mod1$coefficients), 3)[3]
```

In this baseline model, we perform a logistic regression to estimate the odds of O-ring failure using both temperature and pressure as variables

The estimated model is $y = 2.520 - 0.098*Temp + 0.008*Pressure$. 

Using a Wald test, the model returns a p-value of 0.029 for temperature and 0.270 for pressure. Since the p-value for Temperature is below 0.05 (the 95% confidence level), Temperature is statistically significant. The p-value for Pressure is above 0.05 and is not statistically significant at the 95% confidence level. 

Additionally, temperature have a coefficient of -0.098, indicating that an increase in temperature decreases the log odds of O-ring failures. While pressure is not statistically significant, the positive coefficient suggested that an increase in pressure increases the log odds of O-ring failures. These observations are aligned with what we saw from the distribution and box plot charts in the Data section. 

We took this analysis further by computing the odd ratio change of O-ring failure for a 10-unit increase in temperature or pressure. The odds of an O-ring failure is `r OR1` times as likely, or about 63% less likely, for a 10 unit increase in temperature. For a 10-unit The pressure increase, the Odd Ratio is `r OR2` times as likely as no pressure change, which indicates very little impact of pressure increase on the odds of O-ring failure. 

```{asis, echo=FALSE}
2.  Dalal, Fowlkes, and Hoadley (1989) chose to remove `pressure` from the model based on their likelihood ratio tests. Critically evaluate, using your test results and understanding of the question and data, whether `pressure` should be included in the model, or instead, `pressure` should not be included in the model. Your report needs to make a determination, argue why it is most appropriate choice, and make note of how (if at all) the model results are affected by the choice of including or excluding `pressure`.
```

As noted in the above Wald test, Pressure is not statistically significant. We further performed the Likelihood Ratio (LR) test using Anova function to evaluate the effect of each variable and determine whether Pressure should be kept or removed from the model.
```{r LRT-for-model-1, message=FALSE}
Anova(mod1, test = "LR")
```

In the the LR test, we stated a null hypothesis that $\beta_2 = 0$, or Pressure does not add significant explanatory power for the odds of O-ring failure, on top of Temperature in the model. 

From this test, we obtained a p-value for a Chi-squared distribution of 0.0228 for Temperature and 0.2145 for pressure. Like the Wald test, the p-value for Pressure is above 0.05 (the 95% confidence level), so there is not enough evidence to reject the null hypothesis.

Considering both Wald and LR test results, we conclude that Pressure does not add much explanatory power to the model. Excluding it from the model is especially recommended in this case, given the small sample size of 23 observations. The drop in the degree of freedom is 5% when we add one additional explanatory variable. AIC score also decreases with one fewer variable and lower AIC is better. Keeping the model simple and easy to interpret would also help with the further study. 

We removed Pressure from the second model version (mod2) below to simplify the model and noted that this removal does not have too much impact on temperature coefficient. Temperature coefficient is -0.1156 in mod2, instead of -0.098 in mod1.


## Confidence Intervals (20 points)

```{asis, echo=FALSE}
No matter what you determined about using or dropping `pressure`, for this section begin by considering the simplified model $logit(\pi) = \beta_0 + \beta_1 Temp$, where $\pi$ is the probability of an O-ring failure.
Complete the following:

1.  Estimate the logistic regression model.
2.  Determine if a quadratic term is needed in the model for the temperature in this model.
3.  Construct two plots:
4.  $\pi$ vs. Temp; and,
5.  Expected number of failures vs. Temp.

Specific requirements for these plots:

-   Use a temperature range of 31° to 81° on the x-axis even though the minimum temperature in the data set was 53°.\
-   Include the 95% Wald confidence interval bands for $\pi$ on the plot. Describe, in your analysis of these plots, why the bands much wider for lower temperatures than for higher temperatures?
```

In the analysis, we defined Temperature as our explanatory variable in the second model version (mod2). We performed the LR test using the anova function to determined whether a quadratic term is needed in the logistic regression model. See model summary and test results below.

```{r Estimate Logistic Regression with Temperature Effects}
# Estimate the logistic regression model with Temperature 
mod2 <- glm(formula = cbind(O.ring, Number - O.ring) ~ Temp,
  family = binomial(link = "logit"),
  data = challenger)

# Estimate the logistic regression model including quadratic term
mod3 <- glm(formula = cbind(O.ring, Number - O.ring) ~ Temp + I(Temp^2),
  family = binomial(link = "logit"),
  data = challenger)

```

```{r Determine if quadratic term is needed}
anova(mod2, mod3, test = "Chisq")
```

The anova LR test yielded a p-value of 0.48, much higher than the 0.05 critical value, which means that there is little to no evidence that a quadratic term is statistically significant. Therefore, we will move forward with `mod2` without the quadratic term.

In the following analysis, we used our fitted `mod2` model to estimate the probability of O-ring failures and the number of failures for each launch conditional on the temperature at the launch. The plots below show the estimated results by temperature, with the 95% confidence interval.

```{r Pi-vs-Temp-prediction-and-CI, echo = FALSE, message = FALSE}
mod.beta <- mod2$coefficients
# calculate true wald confidence interval at temperature
wald.CI.true.coverage <- function(mod, x_value) {
  alpha <- 0.5
  predict.data <- data.frame(Temp = x_value)
  linear.pred <- predict(object = mod, newdata = predict.data, type = "link", se = TRUE)
  CI.lin.pred <- linear.pred$fit + qnorm(p = c(alpha / 2, 1 - alpha / 2)) * linear.pred$se.fit
  CI.pi <- exp(CI.lin.pred) / (1 + exp(CI.lin.pred))
  wald.df <- round(data.frame(x_value, lower = CI.pi[1], upper = CI.pi[2]), 4)
  return(wald.df)
}
x_seq <- seq(31, 81, by = 1)
wald.CI.true.matrix <- matrix(data = NA, nrow = length(x_seq), ncol = 3)
counter <- 1
for (x_value in x_seq) {
  wald.df2 <- wald.CI.true.coverage(mod2, x_value)
  wald.CI.true.matrix[counter, ] <- c(x_value, wald.df2$lower, wald.df2$upper)
  counter <- counter + 1
}
# check that the matrix is correct
# wald.CI.true.matrix[1:5, ]
```

```{r plot-pi-vs-temp, echo=FALSE, fig.align='center',fig.align='center', out.width="70%", fig.cap="Temperature Effect on O-ring Failure Probability [Left] and Expected Failure Number [Right]"}
par(mfrow = c(1, 2))
# Reproduce the graph overlaying the same result from the linear model as a comparison
curve(
  expr = exp(mod.beta[1] + mod.beta[2] * x) / (1 + exp(mod.beta[1] + mod.beta[2] * x)),
  xlim = c(31, max(challenger$Temp)),
  ylim = c(0, 1),
  col = "blue",
  sub = expression(pi == frac(e^(beta[0] + beta[1] * Temp), 1 + e^(beta[0] + beta[1] * Temp))),
  main = "Probability of Failure vs. Temperature",
  xlab = "",
  ylab = expression(pi),
  cex.main=0.8,
)
par(new = TRUE)
# plot lower and upper bounds to the existing plot
for (matrix_ind in c(2, 3)) {
  lines(
    x = x_seq,
    y = wald.CI.true.matrix[, matrix_ind],
    ylim = c(0, 1),
    type = "l",
    lty = "dotted",
    col = "red"
  )
}

# Generate the plot for the Expected O-ring Failures by Temperature
curve(
  expr = 6 * exp(mod.beta[1] + mod.beta[2] * x) / (1 + exp(mod.beta[1] + mod.beta[2] * x)),
  xlim = c(31, max(challenger$Temp)),
  ylim = c(0, 6),
  col = "blue",
  sub = expression('Estimated O-ring Failures' == 6 * frac(e^(beta[0] + beta[1] * x), 1 + e^(beta[0] + beta[1] * x))),
  main = "Expected Number of Failures vs. Temperature",
  xlab = "",
  ylab = "Estimated O-ring Failures",
  cex.main=0.8,
)
par(new = TRUE)
# plot lower and upper bounds to the existing plot
for (matrix_ind in c(2, 3)) {
  lines(
    x = x_seq,
    y = 6*wald.CI.true.matrix[, matrix_ind],
    ylim = c(0, 1),
    type = "l",
    lty = "dotted",
    col = "red"
  )
}
```



From the above chart, odds of O-Rings failure declines as temperature increases, as $\beta_1$ is negative. 

The 95% confidence intervals are wider for temperatures lower than 65F and narrower for temperatures greater than 65F. The estimated interval for temperature equal to 30F is about (4,6); this illustrates that we have high variability for the expected number of incidents at the low temperature. when temperature goes above 65F and increases towards 80F, our model estimated the number of O-ring failure declines close to zero. 

The reason for wider confidence interval for lower than 65F is because we have fewer observations below 65F with the minimum temperature in the data set being 53F. The forecast error for the below-65F is larger.

```{asis, echo=FALSE}
3.  The temperature was 31° at launch for the Challenger in 1986. Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval. Discuss what assumptions need to be made in order to apply the inference procedures.
```

Given the temperature of 31F for the Challenger launch in 1986, we used our model to estimate the probability of an O-ring failure and compute a corresponding confidence interval. As shown in the results below, the estimated probability of O-ring failure at 31F temperate is 0.82, with 95% confidence interval of 0.14 to 0.99. This is a very wide confidence interval, as we noted above related to the forecast error for below 65F. 

```{r Prob-at-31-degrees, echo=FALSE, message = FALSE, align='center', include=FALSE}
# Compute the Probability at T=31 degree
params <- dim(summary(mod2)$coefficients)[1]
predict.data <- matrix(
  data = c(1, 31),
  nrow = 1,
  ncol = params
)
linear.combo <- mcprofile(object = mod2, CM = predict.data)
mroz_logit_profile <- confint(linear.combo, level = 0.95)
mroz_logit_ci <- exp(mroz_logit_profile$confint) / (1 + exp(mroz_logit_profile$confint))
mroz_logit_estimate <- exp(mroz_logit_profile$estimate) / (1 + exp(mroz_logit_profile$estimate))
result.profile_lr <- data.frame(
  estimate = mroz_logit_estimate,
  lower = mroz_logit_ci$lower,
  upper = mroz_logit_ci$upper
)
round(result.profile_lr,2)
```

To apply the inference procedures, we assume asymptotic properties of a large sample size, independence of each O-Ring failure and each failure has equal probability. This data set only has 23 observations which does not meet the large sample size assumption. As discussed in the prior section, we also raised concerns over the independence assumption. 


## Bootstrap Confidence Intervals (30 points)

```{asis, echo=FALSE}

Rather than relying on asymptotic properties, consider using a parametric bootstrap, as did Dalal, Fowlkes and Hoadley.
To do this:

1.  Simulate a large number of data sets (n = 23 for each) by re-sampling with replacement from the data.
2.  Estimate a model for each dataset.
3.  Compute the effect at a specific temperature of interest.

To produce a confidence interval, the authors used the 0.05 and 0.95 observed quantiles from the simulated distribution as their 90% confidence interval limits.

Using the parametric bootstrap, compute 90% confidence intervals separately at each integer temperature between 10° and 100° Fahrenheit.

In this section, you should describe your process, justify such a process, and present your results in a way that is compelling for your reader.
```

Statistical bootstrapping is a common method used in order to generate statistics with reasonable confidence. Since we are not able to perform the launching experiment for a large sample size, bootstrapping allows us to simulate such a process. 

In this study, we performed 100-folds bootstrap of the challenger data set so that we can obtain 100 sets of O-ring failures at each temperature ranging from $10^o$ to $100^o$ Fahrenheit. It is worth mentioning that at each iteration, we re-sampled 23 observations from the original challenger data set with replacement. This sampling technique ensures that we do not have the same set of values in each iteration while allowing for repeating observations in the sample. 

After the data set is re-sampled, we used this new data set to fit a model for the log odds of an O-ring failure using only temperature as explanatory variable. By fitting a new model for each re-sampled data set, we are able to obtain a slightly different coefficient that would ultimately yield a slightly different prediction at each iteration. 

Finally, we record the probability of an O-ring failure as well as the 90% Wald confidence interval limits given an integer temperature between $10^o$ to $100^o$ Fahrenheit using the re-sampled model. 

```{r resample with replacement, echo = FALSE, message=FALSE}
# for each data set:
# for each model from the resulting data set:
# compute the probability at each integer temeprature value (10 to 100)
# compute the CI for the probability
temp <- NULL
pi.hat <- NULL
CI.lower <- NULL
CI.upper <- NULL
for (i in 1:100) {
  challenger_resampled <- NULL
  # creating a resampled data from the original dataset with replacement
  challenger_resampled <- challenger[sample(nrow(challenger), size = 23, replace = TRUE), ]
  # construct a model from the new resampled dataset
  mod_resample <- glm(
    formula = cbind(O.ring, Number - O.ring) ~ Temp,
    family = binomial(link = "logit"),
    data = challenger_resampled
  )
  output <- NULL
  conf.lower <- NULL
  conf.upper <- NULL
  tprime <- NULL
  # run the model though to obtain the output
  for (t in 10:100) {
    new.data <- data.frame("Temp" = t)
    pred.prob <- predict(mod_resample, newdata = new.data, type = "link", se = TRUE)
    # compute probability and CI
    pi <- exp(pred.prob$fit) / (1 + exp(pred.prob$fit))
    linear.Wald.CI <- pred.prob$fit + qnorm(p = c(0.05, 0.95)) * pred.prob$se
    Wald.CI <- exp(linear.Wald.CI) / (1 + exp(linear.Wald.CI))
    # append data to array
    tprime <- c(tprime, t)
    output <- c(output, pi)
    conf.lower <- c(conf.lower, Wald.CI[1])
    conf.upper <- c(conf.upper, Wald.CI[2])
  }
  # append each bootstrap run
  temp <- c(temp, tprime)
  pi.hat <- c(pi.hat, output)
  CI.lower <- c(CI.lower, conf.lower)
  CI.upper <- c(CI.upper, conf.upper)
}
bootstrap_ouptuts <- data.frame(
  temp = temp, pi.hat = pi.hat,
  lower = CI.lower, upper = CI.upper
)
agg_tbl <- bootstrap_ouptuts %>%
  group_by(temp) %>%
  summarise(
    pi.hat = mean(pi.hat),
    lower = mean(lower),
    upper = mean(upper)
  )

# data.frame(Temperature=agg_tbl$temp, Probability_Estimate=agg_tbl$pi.hat, CI.Lower=agg_tbl$lower, CI.Upper=agg_tbl$upper)[1:5,]
```

From the results obtained from the above procedures, we sliced the data on two temperatures values $31^o$ F and $53^o$ F to reference the temperature at which the Challenger space shuttle launch failed and the lowest launch temperature of the prior launches. From the two temperate data points, we generated the probability distribution histogram of our 100 bootstrap sampled as well as the Q-Q plot to illustrate the predicted probability deviations versus the theoretical Gaussian distribution. 

Figure 4 below shows the probability distribution at $31^o$ F. While the estimated O-ring failure probability distribution is sparse, it does show a high distribution concentration between 0.7 and 1.0. In contrast, the failure probability distribution at $53^o$ F shown in Figure 5 is more Gaussian-like and aggregate at the low probability region between 0.0 and 0.4. 

The Q-Q plots shown in Figure 4 and Figure 5 for both temperatures values further support this by showing the predicted failure probability versus the theoretical failure probability at each quantile. Note that the $53^o$ F Q-Q plot shows an almost 1-1 match between the the quantiled probabilities while there is a clear deviation near the tail ends for the $31^o$ F Q-Q plot. 
```{r Bootstrap-Probability-Distribution-and-QQ-plots-T-31, echo=FALSE, message=FALSE, fig.align='center', out.width="60%", fig.cap="Bootstrap Distribution at T=$31^o$ F"}

# sliced the data on 1 temperature unit
# we chose 31 here since that was what the Challenger launch at
t <- 31
sliced_df <- bootstrap_ouptuts[bootstrap_ouptuts$temp == t, ]
# Draw two plots next to each other
par(mfrow = c(1, 2))
zs <- seq(0, 1, 0.01)
hist_ <- function(x, ...) {
  hist(x, breaks = 30, xlab = "Z", ylab = "", yaxt = "n", freq = FALSE, ...)
  # lines(zs, normal_density, type = "l", col = "red", lwd = 2)
}
hist_(as.numeric(sliced_df$pi.hat), main = "T = 31F O-ring Failure Probability Distribution", xlim = c(0, 1), , cex.main=0.8)
qqnorm(as.numeric(sliced_df$pi.hat), cex.main=0.9 )
qqline(as.numeric(sliced_df$pi.hat), col = "blue", lwd = 2)

```

```{r Bootstrap-Probability-Distribution-and-QQ-plots-T-53, echo=FALSE, message=FALSE, fig.align='center', out.width="60%", fig.cap="Bootstrap Distribution at T=$53^o$ F"}
# sliced the data on 1 temperature unit
# we chose 53 here due to the lowest launch reference temperature
t <- 53
sliced_df <- bootstrap_ouptuts[bootstrap_ouptuts$temp == t, ]
# Draw two plots next to each other
par(mfrow = c(1, 2))
zs <- seq(0, 1, 0.01)
hist_ <- function(x, ...) {
  hist(x, breaks = 30, xlab = "Z", ylab = "", yaxt = "n", freq = FALSE, ...)
  # lines(zs, normal_density, type = "l", col = "red", lwd = 2)
}
hist_(as.numeric(sliced_df$pi.hat), main = "T = 53F O-ring Failure Probability Distribution", xlim = c(0, 1), cex.main=0.8)
qqnorm(as.numeric(sliced_df$pi.hat), cex.main=0.9)
qqline(as.numeric(sliced_df$pi.hat), col = "blue", lwd = 2)
```

It is reasonable to assume that if we're able to replicate the launch measurement at each temperature values 100 more times, we'll have a better idea of the probability of failure at each temperature. Using the bootstrapping method, we're able to better estimate the effect of launch temperature on the odds of an O-ring failure. In short, the temperature at which the Challenger space craft was launched at, $31^o$ F has a really high probability of O-ring failure. Delaying the launch to a warmer temperature would have helped avoiding the failed outcomes.

## Alternative Specification (10 points)

```{asis, echo=FALSE}
With the same set of explanatory variables in your final model, estimate a linear regression model.
Explain the model results; conduct model diagnostic; and assess the validity of the model assumptions.
Would you use the linear regression model or binary logistic regression in this case?
Explain why.
```

We considered the linear regression model as an alternative model selection. Since our statistical tests of the logistic regression models showed that pressure was not statistically significant, we only used temperature as an explanatory variable in the linear regression model to estimate the probability of failure. In this model (see the model form below), we defined the response variable as the number of O-rings failed divided by the total number of O-rings. We obtained a p-value of 0.013 for temperature, which is lowered than the stated 95% Wald confidence level, or alpha 0.05 and visualized by 1 asterisk. The negative coefficient for temperature suggests that at an increase in pressure decreases the probability of failure. 

While the linear model generates reasonable coefficients, this approach is not suitable for this data set because the estimated probability of O.ring failure could fall outside of 0 and 1. Additionally, the linear regression model assumes that the probability of O-ring failure is linearly related to the explanatory variable, temperature in this case, that is not necessarily true. Figure 6 below also showed that it violates the homoskedasticity assumption, noting that the residuals versus fitted values line is not flat around 0. For those reasons, we will use a binary regression model for this data set, instead of the linear regression model.

```{r linear model fit}
model.linear <- lm(formula = I(O.ring / Number) ~ Temp, data = challenger)
```
```{r echo=FALSE, include=FALSE}
Regressionp <- function (modelobject) {
   if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
   f <- summary(modelobject)$fstatistic
   p <- pf(f[1],f[2],f[3],lower.tail=F)
   attributes(p) <- NULL
   return(p) }
print(paste0('P-value is ', round(Regressionp(model.linear),3)))
```
```{r echo=FALSE, message=FALSE, fig.align='center', out.width="70%", fig.cap="Linear Regression Residuals"}
# checking linear model Homeoskedasticity
par(mfrow = c(2, 2)) # init 4 charts in 1 panel
plot(model.linear)
```
# Conclusions (10 points)
```{asis, echo=FALSE}
Interpret the main result of your preferred model in terms of both odds and probability of failure.
Summarize this result with respect to the question(s) being asked and key takeaways from the analysis.
```

```{r echo=FALSE}
OR <- round(exp(10 * coef(mod2)), 4)[2]

```

In conclusion, our final model (see Table 2 below) is the logistic regression model with O-ring success as the response variable and temperature as the explanatory variable. When temperature increases by 1-unit, the odds of O-ring failure will decrease by taking the exponent of the coefficient of 0.116. When temperature increases by 10 degrees is, the odds of O-ring failure is `r OR` times as large as the original temperature, which is about 69% decrease. Figure 3 above shows the estimated probability of O-ring failure and confidence interval at each temperature. 

We conducted Wald and LR test to evaluate the importance of several explanatory variables (Temperature, Pressure, and quadratic term of Temperature). Our test results demonstrate that the logistic regression model with Temperature as the only explanatory variable is the most robust model. This answers the research question and concludes that temperature affects the odds of O-ring failure, but pressure does not have much effect. Given the negative coefficient of temperature, the probability of O-ring failure decreases as temperature increases.  The confidence interval also dramatically narrows when temperature is greater than 65 degrees, compared to less than 65 degrees. 

This observation is reinforced through parametric bootstrapping. With 100 iterations of bootstrapping and 23 observations per iteration, the results showed that at the temperature of 31F, the failure probability distribution is sparse but concentrates at a high probability region between 0.7 and 1.0. However, at 53F, the failure probability distribution is Gaussian-like and aggregates at a low probability region between 0.0 and 0.4. Therefore, delaying the launch to a warmer temperature could significantly decrease the probability of O-ring failure. Finally, we considered a linear regression model as an alternative model, but doing so would causes the probability of failure to be outside of the 0 to 1 range. Furthermore, the linear regresson model would violates the assumption that the probability is linearly related to the explanatory variable as well as the homoskedasticity assumption.

```{r model-2-stargazer, results = "asis",  message = FALSE, echo=FALSE, warning=FALSE}
stargazer(mod2,  header=FALSE,
  type = "latex", omit.stat = c("f", "ser"),
  covariate.labels = c("Temperature", "(Intercept)"),
  report = ("vc*p"),
  star.cutoffs = c(0.05, 0.01, 0.001),
  title = "The Estimated Relationship Between O-Rings Failure and Temperature",
  dep.var.caption = "Output Variable: Log Odds of O-Rings Failure",
  dep.var.labels = "",
  column.sep.width = "-8pt"
)
```
